layers:
- layer_type: !Dense
    input_size: 128
    output_size: 128
  activation:
    activation_type: ReLU
    temperature: null
- layer_type: !Dense
    input_size: 128
    output_size: 10
  activation:
    activation_type: ReLU
    temperature: null
