searchState.loadedDescShard("learn", 0, "Phenotype Trait\nRandomNumberGenerator\nBreedStrategy\nEvolutionOptions\nCalculates the fitness score of a given phenotype.\nManages the evolution process using a specified breeding …\nRepresents the result of an evolution, containing a …\nEvolves a population of phenotypes over multiple …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates a new <code>EvolutionLauncher</code> instance with the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nManages the evolution process using a specified breeding …\nEvolves a population of phenotypes over multiple …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new <code>EvolutionLauncher</code> instance with the …\nPerforms crossover with another individual of the same …\nPerforms mutation on the individual using the provided …\nGenerates a specified number of random floating-point …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nBreedStrategy\nBoundedBreedStrategy\nBreeds new individuals based on a set of parent …\nOrdinaryStrategy\nBoundedBreedStrategy\nBreeds offspring from a set of parent phenotypes, ensuring …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nOrdinaryStrategy\nBreeds new individuals based on a set of parent …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nGenerate a new neural network using a genetic algorithm\nCalls <code>U::from(self)</code>.\nSave the current winner to disk\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nA trait for activation functions used in neural networks. …\nComputes the gradient of the activation function for …\nApplies the activation function to the input vector.\nReturns the name of the activation function.\nReLU (Rectified Linear Unit) activation function.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSigmoid activation function.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new Sigmoid instance.\nSoftmax activation function.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new Softmax instance with the specified …\nTanh activation function.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new Tanh instance.\nA fully connected neural network layer (Dense layer).\nBackward pass for the dense layer\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new DenseLayer with given input and output sizes.\nUpdate weights and biases using their respective gradients\nProvides methods for the forward pass, backward pass, …\nAdjusts the weights according to the Adam optimizer.\nAssigns the weight of the input other layer\nPerforms the backward pass of the layer, computing the …\nPerforms the backward pass of the layer for inputs doing …\nPerforms the forward pass of the layer, computing the …\nPerforms the forward pass of the layer for inputs doing …\nReturns the biases of the layer.\nReturns the weights of the layer.\nReturns the input size of the layer.\nReturns the output size of the layer.\nReads the layer from a file at the specified path.\nResizes the layer to the input dimensions.\nSaves the layer to a file at the specified path.\nUpdates the weights of the layer based on the specified …\nImmutable row iterator\nMutable row iterator\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns an iterator over the rows of the matrix (immutable)\nReturns an iterator over the rows of the matrix (mutable)\nA neural network.\nPerforms a backward pass through the network with the …\nPerforms a backward pass through the network with the …\nPerforms a forward pass through the network with the given …\nPerforms a forward pass through the network with the given …\nReturns the argument unchanged.\nCreates a new <code>NeuralNetwork</code> from the given model directory.\ngets a subnetwork from the neural network according to the …\nReturns the input size of the first layer in the network.\nCalls <code>U::from(self)</code>.\nCreates a new <code>NeuralNetwork</code> from the given shape.\nReturns the output size of the last layer in the network.\nMakes a prediction based on a single input by performing a …\nTrains the neural network using the given inputs, targets, …\nTrains the neural network doing batch back propagation.\nEnum representing the type of activation function used in …\nA fully connected (dense) layer with specified input and …\nStruct representing the shape and configuration of a …\nEnum representing the type of layer in a neural network. …\nStruct representing the shape and configuration of an …\nReLU (Rectified Linear Unit) activation function.\nSigmoid activation function.\nSoftmax activation function.\nTanh (Hyperbolic Tangent) activation function.\nThe activation function used in the layer (e.g., ReLU, …\nAdds a new layer at the specified position.\nChanges layer at the specified position.\nCut out a subnetwork from the neural network shape.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreates a new <code>NeuralNetworkShape</code> with the given layers …\nReturns the layer at the specified index.\nReturns the input size of the layer.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nChecks if the layer shape is valid.\nChecks if the neural network shape is valid.\nReturns the type of the layer.\nThe type of the layer (e.g., Dense) with input and output …\nA vector of <code>LayerShape</code> structs, representing each layer in …\nCreates a new <code>NeuralNetworkShape</code> with the given layers.\nReturns the number of layers in the neural network shape.\nReturns the output size of the layer.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nget the resulting neural network\nCalls <code>U::from(self)</code>.\nSave the model to disk")