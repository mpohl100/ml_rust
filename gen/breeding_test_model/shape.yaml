layers:
- layer_type: !Dense
    input_size: 128
    output_size: 128
  activation:
    activation_type: ReLU
    temperature: null
- layer_type: !Dense
    input_size: 128
    output_size: 64
  activation:
    activation_type: ReLU
    temperature: null
- layer_type: !Dense
    input_size: 64
    output_size: 10
  activation:
    activation_type: Sigmoid
    temperature: null
